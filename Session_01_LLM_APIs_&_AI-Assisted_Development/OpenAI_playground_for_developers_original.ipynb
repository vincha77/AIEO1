{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPtFBgj623FS"
      },
      "source": [
        "# Developing with OpenAI: AIM Edition\n",
        "\n",
        "## Exploring LLM Prompting Strategies for Economic Reasoning  \n",
        "### *Inflation & Interest Rate Case Study*\n",
        "\n",
        "This notebook investigates how different prompting strategies (zero-shot, few-shot, reasoning vs non-reasoning models) affect the ability of large language models (LLMs) to reason about inflation, interest rates, and overall market dynamics.  \n",
        "\n",
        "We also retain all the previous instructional structure and code scaffolding to maintain a complete, comprehensive educational example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4egfB274VD"
      },
      "source": [
        "## 1. Getting Started\n",
        "\n",
        "The first thing we'll do is load the [OpenAI Python Library](https://github.com/openai/openai-python/tree/main)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23H7TMOM4mfy",
        "outputId": "698578e4-f787-41d6-fe93-249b8af78b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Used for Google Colab\n",
        "#!pip install openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Discussion and Problem Framing\n",
        "\n",
        "We aim to answer:  \n",
        "> *\"What is the best prompting approach and model type to understand how the market is performing today?\"*  \n",
        "\n",
        "### Types of LLM Tasks Involved\n",
        "\n",
        "| Type | Description | Example Output |\n",
        "|------|--------------|----------------|\n",
        "| **Retrieval** | Factual recall | ‚ÄúInflation in 2025 is around 3.1% in the U.S.‚Äù |\n",
        "| **Reasoning** | Logical chain between variables | ‚ÄúHigher inflation led the Fed to raise rates ‚Üí borrowing costs rose ‚Üí slower GDP.‚Äù |\n",
        "| **Generation** | Narrative creation / summary | ‚ÄúThe market shows cooling signals despite moderate inflation‚Ä¶‚Äù |\n",
        "\n",
        "Each prompt and model will be evaluated on reasoning depth, factual correctness, and structure quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Used models in this repo\n",
        "\n",
        "| Rank | Model Name | Primary Purpose | OpenAI's Official Claim |\n",
        "|------|------------|-----------------|------------------------|\n",
        "| 1 | **GPT-5** | Advanced reasoning for complex economic analysis | Uses a dynamic router that chooses between quick responses and deeper 'thinking' when needed; performs at PhD-level across domains |\n",
        "| 2 | **GPT-4.1** | Enhanced coding and long-context comprehension | Offers significant advancements in coding capabilities, long context comprehension (up to 1M tokens), and instruction following |\n",
        "| 3 | **GPT-4-turbo** | General-purpose non-reasoning model for structured responses | Improved version of GPT-4 with enhanced performance, lower latency, and updated knowledge cutoff |\n",
        "| 4 | **GPT-4o-mini** | Fast, efficient model for quick responses | Cost-efficient AI model designed to make advanced AI technology more affordable and accessible |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKD8XBTVEAOw"
      },
      "source": [
        "## 2. Setting Environment Variables\n",
        "\n",
        "As we'll frequently use various endpoints and APIs hosted by others - we'll need to handle our \"secrets\" or API keys very often.\n",
        "\n",
        "We'll use the following pattern throughout this bootcamp - but you can use whichever method you're most familiar with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGU9OMvhEPG0",
        "outputId": "2609c2ff-e2f5-4464-fb26-38a4fcfe7ea3"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "# import os\n",
        "# import getpass\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For local development\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dabxI3MuEYXS"
      },
      "source": [
        "## 3. Using the OpenAI Python Library\n",
        "\n",
        "Let's jump right into it!\n",
        "\n",
        "> NOTE: You can, and should, reference OpenAI's [documentation](https://platform.openai.com/docs/api-reference/authentication?lang=python) whenever you get stuck, have questions, or want to dive deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbCbNzPVEmJI"
      },
      "source": [
        "### Creating a Client\n",
        "\n",
        "The core feature of the OpenAI Python Library is the `OpenAI()` client. It's how we're going to interact with OpenAI's models, and under the hood of a lot what we'll touch on throughout this course.\n",
        "\n",
        "> NOTE: We could manually provide our API key here, but we're going to instead rely on the fact that we put our API key into the `OPENAI_API_KEY` environment variable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "LNwZtaE-EltC"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDxUkDbFBPI"
      },
      "source": [
        "### Using the Client\n",
        "\n",
        "Now that we have our client - we're going to use the `.chat.completions.create` method to interact with the model.\n",
        "\n",
        "There's a few things we'll get out of the way first, however, the first being the idea of \"roles\".\n",
        "\n",
        "First it's important to understand the object that we're going to use to interact with the endpoint. It expects us to send an array of objects of the following format:\n",
        "\n",
        "```python\n",
        "{\"role\" : \"ROLE\", \"content\" : \"YOUR CONTENT HERE\", \"name\" : \"THIS IS OPTIONAL\"}\n",
        "```\n",
        "\n",
        "Second, there are three \"roles\" available to use to populate the `\"role\"` key:\n",
        "\n",
        "- `system`\n",
        "- `assistant`\n",
        "- `user`\n",
        "\n",
        "OpenAI provides some context for these roles [here](https://help.openai.com/en/articles/7042661-moving-from-completions-to-chat-completions-in-the-openai-api).\n",
        "\n",
        "We'll explore these roles in more depth as they come up - but for now we're going to just stick with the basic role `user`. The `user` role is, as it would seem, the user!\n",
        "\n",
        "Thirdly, it expects us to specify a model!\n",
        "\n",
        "We'll use the `gpt-5-mini` model as stated above.\n",
        "\n",
        "Let's look at an example!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "2RpNl6yNGzb0"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc_UbpwNHdrM"
      },
      "source": [
        "Let's look at the response object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsXJtvxRHfoM",
        "outputId": "3b28ce47-a765-4446-b0f9-33738e385b96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CW0aOq06K8Y5uOms3gibr0v00A6uN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today? (I can answer questions, draft or edit text, help with coding, explain concepts, plan things, or anything else you need.)', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761744784, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=109, prompt_tokens=8, total_tokens=117, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=64, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I help you today? (I can answer questions, draft or edit text, help with coding, explain concepts, plan things, or anything else you need.)\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy9kSuf1Hiv5"
      },
      "source": [
        ">NOTE: We'll spend more time exploring these outputs later on, but for now - just know that we have access to a tonne of powerful information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZ8gjiAISyd"
      },
      "source": [
        "### System Role\n",
        "\n",
        "Now we can extend our prompts to include a system prompt.\n",
        "\n",
        "The basic idea behind a system prompt is that it can be used to encourage the behaviour of the LLM, without being something that is directly responded to - let's see it in action!\n",
        "\n",
        "In the newest OpenAI API, the **system message** still defines the model‚Äôs behavior.  \n",
        "Sometimes it is referred to as an *instruction block*.\n",
        "\n",
        "Example system prompt for our economics case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are an experienced economic analyst explaining how inflation and interest rates interact.   \n",
            "Use 2025 U.S. market context when relevant.\n",
            "Your answer should not exceed 5 sentences. \n",
            "\n",
            "What is the relationship between inflation and interest rates?\n",
            "Inflation and interest rates are closely related in economic management, primarily through central bank policies such as those of the Federal Reserve. Typically, when inflation rates rise, central banks may increase interest rates to cool down the economy by making borrowing more expensive, thereby reducing spending and slowing inflation. Conversely, if inflation is low, central banks might lower interest rates to encourage borrowing and spending, which can help stimulate the economy. For instance, if by 2025, the U.S. experiences higher inflation rates, the Federal Reserve might respond by hiking interest rates to prevent the economy from overheating. This interaction plays a crucial role in maintaining economic stability by balancing growth and inflationary pressures.\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are an experienced economic analyst explaining how inflation and interest rates interact.   \n",
        "Use 2025 U.S. market context when relevant.\n",
        "Your answer should not exceed 5 sentences. \n",
        "\"\"\"\n",
        "print(system_prompt)\n",
        "\n",
        "user_prompt = \"What is the relationship between inflation and interest rates?\"\n",
        "print(user_prompt)\n",
        "\n",
        "list_of_prompts = [\n",
        "\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]\n",
        "\n",
        "irate_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print(irate_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpyVhotWIsOs"
      },
      "source": [
        "As you can see - the response we get back is very much in line with the system prompt!\n",
        "\n",
        "Let's try the same user prompt, but with a different system to prompt to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "2coVmMn3I0-2",
        "outputId": "571b89a2-9209-4003-d63c-49b653e0d56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are a cool and fun elementary teacher explaining to 6-year olds how inflation and interest rates interact.   \n",
            "Use 2025 U.S. market context when relevant.\n",
            "Your answer should not exceed 5 sentences.\n",
            "\n",
            "What is the relationship between inflation and interest rates?\n",
            "Imagine if you have a piggy bank where you keep saving money to buy your favorite toy. Now, let's pretend the prices of toys start going up ‚Äì that‚Äôs like inflation, where things cost more. The people who decide on interest rates, kind of like the rules for our piggy banks, can make a change. If they make the interest rate higher, it's like encouraging everyone to save more instead of spending, and that can help stop prices from going up too fast. So, in simple words, when things start to cost more, raising interest rates can help keep everything balanced!\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a cool and fun elementary teacher explaining to 6-year olds how inflation and interest rates interact.   \n",
        "Use 2025 U.S. market context when relevant.\n",
        "Your answer should not exceed 5 sentences.\n",
        "\"\"\"\n",
        "print(system_prompt)\n",
        "\n",
        "user_prompt = \"What is the relationship between inflation and interest rates?\"\n",
        "print(user_prompt)\n",
        "\n",
        "list_of_prompts = [\n",
        "\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "]\n",
        "\n",
        "irate_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print(irate_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e13heYNQJAo-"
      },
      "source": [
        "With a simple modification of the system prompt - you can see that we got completely different behaviour, and that's the main goal of prompt engineering as a whole.\n",
        "\n",
        "Also, congrats, you just engineered your first prompt!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VI3zlPJL05"
      },
      "source": [
        "### Few-shot Prompting\n",
        "\n",
        "Now that we have a basic handle on the `system` role and the `user` role - let's examine what we might use the `assistant` role for.\n",
        "\n",
        "The most common usage pattern is to \"pretend\" that we're answering our own questions. This helps us further guide the model toward our desired behaviour. While this is a over simplification - it's conceptually well aligned with few-shot learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "lwxPuCyyJMye",
        "outputId": "ec01213d-6755-4506-8879-cf0870934349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zero-shot response: Inflation significantly influences interest rate decisions made by central banks and financial institutions. Here‚Äôs how this relationship typically works:\n",
            "\n",
            "1. **Central Bank Mandates**: Central banks, such as the Federal Reserve in the U.S., often have a dual mandate: to promote maximum employment and stable prices (low inflation). When inflation rises above targeted levels, central banks may take action to curb it.\n",
            "\n",
            "2. **Interest Rate Adjustments**: To combat rising inflation, central banks may decide to increase interest rates. Higher interest rates make borrowing more expensive, which tends to slow down consumer spending and business investment. This reduction in demand can help lower inflation.\n",
            "\n",
            "3. **Expectations of Future Inflation**: If consumers and businesses expect inflation to rise, they may adjust their behavior accordingly (e.g., demanding higher wages or preemptively raising prices). Central banks may raise interest rates preemptively to manage these expectations and prevent a wage-price spiral, where rising wages and prices continuously feed into one another.\n",
            "\n",
            "4. **Impact on Economic Growth**: While raising interest rates can help control inflation, it can also slow economic growth. Therefore, central banks must balance the need to control inflation with the potential negative impacts on economic expansion. This often involves carefully assessing the current economic environment, including factors like labor market conditions and consumer confidence.\n",
            "\n",
            "5. **Real Interest Rates**: The real interest rate is the nominal interest rate adjusted for inflation. If inflation rises faster than nominal interest rates set by a central bank, the real interest rate can become negative, potentially fostering an environment where borrowing and spending increase further. In response, central banks may raise nominal rates to ensure real rates remain positive, discouraging excessive borrowing.\n",
            "\n",
            "6. **Market Reactions**: Financial markets closely monitor inflation data, and expectations surrounding interest rate changes. If inflation reports are higher than expected, markets may quickly adjust their pricing of future interest rate hikes, impacting everything from bond yields to stock prices.\n",
            "\n",
            "7. **Inflation Targeting Policies**: Many central banks employ inflation targeting as part of their monetary policy framework. This involves setting a specific inflation target (e.g., 2% in many advanced economies) and adjusting interest rates to keep inflation around that target. If inflation consistently exceeds this target, it can lead to a tightening of monetary policy, with higher interest rates to stabilize prices.\n",
            "\n",
            "In summary, inflation is a critical factor in shaping interest rate decisions. Central banks monitor inflation closely to adjust rates accordingly, striving to achieve a balance between controlling inflation and supporting economic growth.\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompt\n",
        "prompt_zero = \"Explain how inflation affects interest rate decisions.\"\n",
        "list_of_prompts = [\n",
        "    {\"role\": \"user\", \"content\": prompt_zero}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print('zero-shot response:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "few-shot response: A: When inflation starts to sizzle like a hot griddle ü•ìüî•, central banks may hike interest rates to cool things down. Higher rates make borrowing costlier, leading everyone to think twice before splurging on those extra treats. This helps keep prices in check and maintains economic stability!\n"
          ]
        }
      ],
      "source": [
        "# Few-shot prompt template\n",
        "\n",
        "question = \"Explain how inflation affects interest rate decisions.\"\n",
        "\n",
        "few_shot_prompt = f\"\"\"\n",
        "Example 1:\n",
        "Q: The price of pizza slices jumps from $2 to $4. What might the central bank do?\n",
        "A: They turn down the oven heat üçïüî• ‚Äî raise interest rates so people buy fewer slices and cool off the price party.\n",
        "\n",
        "Example 2:\n",
        "Q: Interest rates drop and borrowing gets cheaper. What happens at Snack City?\n",
        "A: Everyone's grabbing extra fries and milkshakes üçüü•§‚Äî cheap credit means more spending, which can make prices rise again.\n",
        "\n",
        "Now answer:\n",
        "Q: {question}\n",
        "\"\"\"\n",
        "\n",
        "list_of_prompts = [\n",
        "    {\"role\": \"user\", \"content\": few_shot_prompt}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=list_of_prompts\n",
        ")\n",
        "\n",
        "print('few-shot response:', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions\n",
        "\n",
        "We're going to create some helper functions to aid in using the OpenAI API - just to make our lives a bit easier.\n",
        "\n",
        "> NOTE: Take some time to understand these functions between class!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def get_response(client: OpenAI, messages: list, model: str = \"gpt-4o-mini\") -> str:\n",
        "    return client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "def system_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"system\", \"content\": message}\n",
        "\n",
        "def assistant_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"assistant\", \"content\": message}\n",
        "\n",
        "def user_prompt(message: str) -> dict:\n",
        "    return {\"role\": \"user\", \"content\": message}\n",
        "\n",
        "def pretty_print(message: str) -> str:\n",
        "    display(Markdown(message.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgTVkNmOJQSC"
      },
      "source": [
        "Different way we can do prompting -> using the helper's functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eEZkRJq5JQkQ",
        "outputId": "22170b9c-6212-42de-8469-a7efc9c9405d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's like a dating coach giving you confidence boosters ‚Äî flooding the market with money to encourage spending and invest in relationships (assets) to revive the economy and spark romance (growth).\n"
          ]
        }
      ],
      "source": [
        "# Now, show the economic example with both user and assistant prompts\n",
        "few_shot_prompts = [\n",
        "    user_prompt(\"Inflation rises fast. How does the central bank react ‚Äî dating analogy please!\"),\n",
        "    assistant_prompt(\"They play hard to get ‚Äî raise rates ‚Äî to cool off the economy's over-eager spending habits.\"),\n",
        "\n",
        "    user_prompt(\"What happens when interest rates are too low for too long?\"),\n",
        "    assistant_prompt(\"Everyone gets too comfortable ‚Äî too many relationships (loans) form, and eventually hearts (bubbles) break.\"),\n",
        "\n",
        "    user_prompt(\"Explain deflation using a dating metaphor.\"),\n",
        "    assistant_prompt(\"No one's asking anyone out ‚Äî everyone waits for a better deal, so the economy gets lonely and quiet.\"),\n",
        "    # üëá Here's the actual question we want the model to answer\n",
        "    user_prompt(\"Describe quantitative easing\")\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=few_shot_prompts\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèóÔ∏è Activity #1:\n",
        "Mission:\n",
        "Experiment with how different prompt structures, system, user, and assistant, plus zero-shot and few-shot prompting, can transform an AI‚Äôs response.\n",
        "Your goal: craft the most effective prompt and see how GPT-4-Turbo reacts!\n",
        "\n",
        "You‚Äôll test how GPT-4-Turbo behaves under four different setups:\n",
        "1. System/User roles only (Zero-shot)\n",
        "2. System/User roles + examples (Few-shot)\n",
        "3. No system role at all (User only)\n",
        "4. Creative system prompt twist\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGaLYM3JU-8"
      },
      "source": [
        "### Chain of Thought Prompting\n",
        "\n",
        "We'll head one level deeper and explore the world of Chain of Thought prompting (CoT).\n",
        "\n",
        "This is a process by which we can encourage the LLM to handle slightly more complex tasks.\n",
        "\n",
        "Let's look at a simple reasoning based example without CoT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ltLtF4wEJTyK",
        "outputId": "29c6e20f-edf1-4dfc-de8a-a8410f31b721"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Real wages would decrease in this scenario. With inflation at 5%, prices are rising faster than nominal wages, which are only growing at 3%. This means that purchasing power is being eroded as prices outpace wage growth. As a result, real wages, which take inflation into account, would decrease."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reasoning_problem = \"\"\"\n",
        "The central bank increases the policy rate by 1.5 pp in response to 5 % inflation while nominal wage growth is 3 %.\n",
        "What happens to real wages?\n",
        "\"\"\"\n",
        "\n",
        "list_of_prompts = [\n",
        "    user_prompt(reasoning_problem)\n",
        "]\n",
        "\n",
        "reasoning_response = get_response(client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbqj30CQJnQl"
      },
      "source": [
        "Let's see if we can leverage a simple CoT prompt to improve our model's performance on this task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "A9Am3QNGJXHR",
        "outputId": "83b87232-911c-4ab9-a863-58ecfd10b8a9"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "When the central bank increases the policy rate by 1.5 pp in response to 5% inflation, it is trying to combat the rising prices by tightening monetary policy. This increase in the policy rate will lead to higher borrowing costs for businesses and individuals, which can slow down economic activity and reduce aggregate demand.\n",
              "\n",
              "As a result, businesses may not be able to afford to pay higher wages due to the higher borrowing costs and lower demand for their products/services. This can lead to slower growth in nominal wages, despite the fact that inflation is rising.\n",
              "\n",
              "In this scenario, nominal wage growth is 3%, while inflation is 5%. This means that real wages are actually decreasing, as the purchasing power of wages is being eroded by inflation. Real wages are calculated by adjusting nominal wages for changes in the price level.\n",
              "\n",
              "So, in this case, the real wage effect would be negative - despite workers receiving a 3% increase in wages, their purchasing power has decreased by more than that due to the 5% inflation rate. This highlights the importance of considering both nominal wages and inflation when assessing changes in real wages."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_of_prompts = [\n",
        "    user_prompt(reasoning_problem + \"Think step-by-step about how nominal wages, prices, and interest rates interact through the labor market and aggregate demand. Then explain the real wage effect.\")\n",
        "]\n",
        "\n",
        "reasoning_response = get_response(client, list_of_prompts)\n",
        "pretty_print(reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Running Comparative Experiment\n",
        "\n",
        "We'll test combinations of model type (reasoning vs non-reasoning) and prompting style (zero-shot vs few-shot).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 1: GPT-4-turbo (Non-Reasoning)\n",
            "==============================\n",
            "\n",
            "Zero-Shot Prompting (no examples):\n",
            "\n",
            "A: Inflation erodes the purchasing power of money, meaning that if nominal wages (the face value of wages paid) do not increase at the same rate as inflation, real wages (the purchasing power of those wages) will decline. Essentially, if inflation rises faster than nominal wages, workers can buy less with their earnings, resulting in a decrease in real income and living standards. This can impact consumer spending, savings rates, and overall economic growth. Conversely, if nominal wages increase faster than inflation, real wages rise, enhancing purchasing power and potentially boosting economic activity. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# üß© Comparing GPT Models: Reasoning vs Non-Reasoning\n",
        "# --------------------------------------------------\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an experienced economic analyst.\n",
        "\"\"\"\n",
        "\n",
        "question = \"\"\"What is the impact of inflation on real wages? Respond in a concise manner.\"\"\"\n",
        "\n",
        "prompt_few = f\"\"\"\n",
        "Use this exact format to answer the question:\n",
        "Example 1:\n",
        "{{\n",
        "  \"possible_explanation\": \"Wage catch-up effect\",\n",
        "  \"mechanism\": \"Workers negotiate higher nominal wages to preserve purchasing power as prices rise.\",\n",
        "  \"impact_on_wages\": \"Nominal wages increase roughly in line with inflation, keeping real wages stable in the short run.\",\n",
        "  \"time_frame\": \"Short to medium run\",\n",
        "  \"economic_context\": \"Inflationary periods with strong labor bargaining power or cost-of-living adjustments.\"\n",
        "}}\n",
        "\n",
        "Example 2:\n",
        "{{\n",
        "  \"possible_explanation\": \"Real wage erosion\",\n",
        "  \"mechanism\": \"When nominal wages lag behind price growth, workers lose purchasing power.\",\n",
        "  \"impact_on_wages\": \"Real wages decline despite nominal wage increases, reducing workers‚Äô living standards.\",\n",
        "  \"time_frame\": \"Immediate term\",\n",
        "  \"economic_context\": \"High inflation environments with weak wage indexation or rigid labor contracts.\"\n",
        "}}\n",
        "\n",
        "Now answer:\n",
        "Q: {question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# MODEL 1: GPT-4-turbo  ‚Üí Non-Reasoning\n",
        "# --------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 1: GPT-4-turbo (Non-Reasoning)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Zero-shot\n",
        "answer_nonreasoning_zero_shot = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ],\n",
        ")\n",
        "print(\"Zero-Shot Prompting (no examples):\\n\")\n",
        "print(\"A:\", answer_nonreasoning_zero_shot.choices[0].message.content, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 2: GPT-5 (Reasoning-Tuned)\n",
            "==============================\n",
            "\n",
            "Zero-Shot Prompting (no examples):\n",
            "\n",
            "A: - Real wages are nominal wages adjusted for prices; roughly, real wage growth ‚âà nominal wage growth ‚àí inflation.\n",
            "- If inflation exceeds nominal wage growth, purchasing power falls; if nominal wages grow faster, it rises.\n",
            "- Because wages adjust with lags and many aren‚Äôt fully indexed, unexpected inflation typically cuts real wages in the short run; COLAs/strong bargaining mitigate, while fixed-pay/minimum-wage workers lose more.\n",
            "- Non-indexed tax brackets (bracket creep) can further reduce after‚Äëtax real wages; over time, productivity growth is the key driver of sustained real wage gains. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# MODEL 2: GPT-5  ‚Üí Reasoning\n",
        "# --------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 2: GPT-5 (Reasoning-Tuned)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Zero-shot\n",
        "answer_reasoning_zero_shot = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ],\n",
        ")\n",
        "print(\"Zero-Shot Prompting (no examples):\\n\")\n",
        "print(\"A:\", answer_reasoning_zero_shot.choices[0].message.content, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 1: GPT-4-turbo (Non-Reasoning)\n",
            "==============================\n",
            "\n",
            "Few-Shot Prompting (with examples):\n",
            "\n",
            "A: {\n",
            "  \"possible_explanation\": \"Inflation and real wage dynamics\",\n",
            "  \"mechanism\": \"Inflation reduces the purchasing power of nominal wages unless they are adjusted at the same rate or faster.\",\n",
            "  \"impact_on_wages\": \"Real wages decline if wage increases do not keep pace with inflation, eroding worker purchasing power.\",\n",
            "  \"time_frame\": \"Can be immediate or gradual, depending on inflation rate and wage adjustment frequency.\",\n",
            "  \"economic_context\": \"Periods of sustained inflation without corresponding and timely wage adjustments.\"\n",
            "} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 1: GPT-4-turbo (Non-Reasoning)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Few-shot\n",
        "answer_nonreasoning_few_shot = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ],\n",
        ")\n",
        "print(\"Few-Shot Prompting (with examples):\\n\")\n",
        "print(\"A:\", answer_nonreasoning_few_shot.choices[0].message.content, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "MODEL 2: GPT-5 (Reasoning-Tuned)\n",
            "==============================\n",
            "\n",
            "Few-Shot Prompting (with examples):\n",
            "\n",
            "A: {\n",
            "  \"possible_explanation\": \"Real wage erosion\",\n",
            "  \"mechanism\": \"If nominal wage growth trails inflation, purchasing power falls.\",\n",
            "  \"impact_on_wages\": \"Real wages decline until nominal wages catch up.\",\n",
            "  \"time_frame\": \"Immediate to short run\",\n",
            "  \"economic_context\": \"High or accelerating inflation with limited wage indexation or weak bargaining power.\"\n",
            "} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==============================\")\n",
        "print(\"MODEL 2: GPT-5 (Reasoning-Tuned)\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "# Few-shot\n",
        "answer_reasoning_few_shot = client.chat.completions.create(\n",
        "    model=\"gpt-5\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ],\n",
        ")\n",
        "print(\"Few-Shot Prompting (with examples):\\n\")\n",
        "print(\"A:\", answer_reasoning_few_shot.choices[0].message.content, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Evaluation Framework\n",
        "\n",
        "LLM as a judge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Parsed JSON Result:\n",
            "{\n",
            "  \"Answer A Score\": 4,\n",
            "  \"Answer B Score\": 3,\n",
            "  \"Better Answer\": \"A\",\n",
            "  \"Explanation\": \"Both answers are factually correct: inflation reduces real wages if nominal wages do not rise as fast. Answer A is slightly better reasoned and more complete \\u2014 it notes the role of timely wage adjustments and allows for immediate or gradual effects depending on inflation rate and adjustment frequency, capturing the key interdependency between inflation and wage-setting. Answer B is accurate but narrower (emphasizing the short run) and omits the explicit role of adjustment timing that A highlights, so it receives a lower score.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# --------------------------------------------------\n",
        "# ‚öñÔ∏è LLM-as-a-Judge Evaluation Script\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Define evaluation scale (0‚Äì4)\n",
        "# 0 = completely incorrect / irrelevant\n",
        "# 1 = partially correct but weak or inaccurate reasoning\n",
        "# 2 = fair factual accuracy, minimal reasoning\n",
        "# 3 = accurate and somewhat reasoned\n",
        "# 4 = highly accurate, clear causal explanation, correct logic\n",
        "\n",
        "evaluation_prompt = f\"\"\"\n",
        "You are an impartial economics teacher grading two student answers to the same question.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer A (non-reasoning model):\n",
        "{answer_nonreasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "Answer B (reasoning model):\n",
        "{answer_reasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "Evaluate both answers on accuracy and reasoning quality on a 0‚Äì4 scale:\n",
        "- 0 = completely incorrect or irrelevant\n",
        "- 1 = partially correct, but flawed\n",
        "- 2 = fair factual accuracy, limited reasoning\n",
        "- 3 = mostly correct, some reasoning\n",
        "- 4 = fully accurate and clearly reasoned, ability to see the interdependencies between variables.\n",
        "\n",
        "Return your evaluation as a JSON object in this exact format:\n",
        "{{\n",
        "  \"Answer A Score\": <0-4>,\n",
        "  \"Answer B Score\": <0-4>,\n",
        "  \"Better Answer\": \"A\" or \"B\",\n",
        "  \"Explanation\": \"Why the better answer is more accurate or reasoned\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# Choose a strong evaluator model (GPT-4.1 is good for judging)\n",
        "evaluation = client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an impartial LLM evaluator for economics-related answers.\"},\n",
        "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Parse and display the evaluation\n",
        "response_text = evaluation.choices[0].message.content\n",
        "\n",
        "# Optional: try to parse JSON for structured output\n",
        "try:\n",
        "    result = json.loads(response_text)\n",
        "    print(\"\\nParsed JSON Result:\")\n",
        "    print(json.dumps(result, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nNote: Could not parse JSON, model may have returned free text instead.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üèóÔ∏è Activity #2:\n",
        "\n",
        "Evaluate different prompting strategies using your own example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Reasoning model answer saved to: /Users/katerinag/Documents/AIE/on-ramp/Lesson1/results.md\n"
          ]
        }
      ],
      "source": [
        "# Create markdown content\n",
        "markdown_content = f\"\"\"\n",
        "# üß† Reasoning Model Answer\n",
        "### Question:\n",
        "How does inflation affect interest rates and the broader market?\n",
        "\n",
        "### Model Used:\n",
        "`gpt-4.1` (Reasoning-tuned)\n",
        "\n",
        "### Response:\n",
        "{answer_reasoning_few_shot.choices[0].message.content}\n",
        "\n",
        "---\n",
        "\n",
        "*This answer was generated by a reasoning model to illustrate step-by-step economic reasoning.*\n",
        "\"\"\"\n",
        "\n",
        "output_path='./results.md'\n",
        "# Save to file\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(markdown_content)\n",
        "\n",
        "print(f\"‚úÖ Reasoning model answer saved to: {os.path.abspath(output_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "- **Few-shot prompts** improve structure and reasoning consistency.  \n",
        "- **Reasoning models** (like GPT-5-reasoning) deliver more coherent causal explanations between inflation, interest rates, and growth indicators.  \n",
        "- **Non-reasoning models** (e.g., GPT-5-mini) provide faster, surface-level insights ideal for retrieval or summarization tasks.  \n",
        "- Future work could add **RAG pipelines** with real-time macroeconomic data or integrate with financial dashboards for live LLM reasoning visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
